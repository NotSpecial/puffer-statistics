# puffer-statistics

Dumps and analyzes the raw data recorded by [Puffer](https://puffer.stanford.edu/), a TV streaming website and Stanford research study. Anyone can download the daily data, build the analysis programs, and run the pipeline themselves. We encourage the public to replicate our results, posted every day along with the anonymized [raw data](https://console.cloud.google.com/storage/browser/puffer-stanford-public/data-release-test) (TODO: link to prod bucket and results webpage).


## Setup
To set up a machine for the analysis, see `scripts/init_data_release_vm.sh`. This installs the dependencies listed in `scripts/deps.sh`, creates a local directory `~/data-release-test` for the results, and builds the analysis programs. 

Note that `scripts/deps.sh` installs packages as `sudo`, so users may prefer to manage dependencies on their own. Dependencies marked as "private" in the script are not required for users. 

The analysis pipeline has been tested on Ubuntu 19.10. 

## Pipeline Overview
The "entrance program" in `scripts/entrance.sh` executes the analysis pipeline. Given a date, this program outputs CSVs containing the day’s (anonymized) raw data, as well as stream and scheme statistics. Scheme statistics are calculated over the day as well as several time periods preceding it (week, two-week, and month). 

The entrance program runs in private mode daily on the Puffer server, pushing the results to the [data-release bucket](https://console.cloud.google.com/storage/browser/puffer-stanford-public/data-release-test). After this, the entrance program can be run in public mode, using the CSVs in the bucket as input. Users outside the Puffer organization lack the permissions to run in private mode.

To run the entrance program:

`scripts/entrance.sh [current | 20XX-XX-XXT11_20XX-XX-XXT11] (private)` 

The date may be the current day or some past day. 20XX-XX-XXT11_20XX-XX-XXT11 is the Influx backup to be analyzed (TODO: easier arg format).  

If running in public mode, the CSVs for the desired day must already be in the [data-release bucket](https://console.cloud.google.com/storage/browser/puffer-stanford-public/data-release-test). 

## Pipeline Components
We recommend using `scripts/entrance.sh` to dump and analyze data, rather than running its component programs individually. However, the public is able to run all components of the pipeline except `private_analyze`, which requires Puffer-specific permissions.    

As shown in the diagram below, the data pipeline has three stages, executed by `private_analyze`, `public_analyze`, and `confinterval`, respectively. The final stage requires two metadata files generated by `pre_confinterval`: `scheme intersection` and `watch times`, described below. 

![Alt text](https://raw.githubusercontent.com/StanfordSNR/puffer-statistics/data-release/img/pipeline.svg?sanitize=true)


### Puffer background
Loading the Puffer video player starts a new streaming "session". Each channel change starts a new "stream" within the session. Each session is randomly assigned a "scheme" on load. A scheme, e.g. `Fugu/BBR` or `Pensieve/Cubic`, is the set of adaptive bit rate and congestion control algorithms used for the duration of a session. An "experiment" is the group of schemes from which each session’s scheme is randomly chosen. This group of schemes changes over time, as new experiments are performed. See the Puffer [paper](https://sophon.stanford.edu/static/puffer/documents/puffer-paper.pdf) for further detail. 

### `scheme intersection` 

The `scheme intersection` file (i.e. `intx_out.txt`) lists the days on which *all* schemes in the desired day’s experiment were run (see [Scheme Statistics](#scheme-statistics) for why this is necessary). 

To produce the intersection file, first an experiment-agnostic `scheme schedule` (i.e. `scheme_days_out.txt`) is generated. The schedule enumerates the days each scheme ran, for schemes that appeared in *any* experiment(s) in the input data. For convenience, `pre_confinterval` also outputs a more human-readable `scheme schedule` in `scheme_days_err.txt`. 

Given an experiment and a `scheme schedule`, `pre_confinterval` filters the `scheme schedule` to days on which *all* schemes in the experiment ran. For instance, if the `scheme schedule` is  
`{ Fugu/BBR  => Jan 1 : Jan 4, BBA/BBR => Jan 4 : Jan 5, Pensieve/BBR => Jan 3 : Jan 5 }` and the experiment is `{ Fugu/BBR, Pensieve/BBR }`, then the `scheme intersection` is `{ Jan 3 : Jan 4 }`, since both schemes in the experiment ran on those days.

As shown in the diagram above, the entrance program uses the same `scheme schedule` and `scheme intersection` for all time periods leading up to a given day. In fact, these two files can be generated from any input data range inclusive of all desired periods. Since the monthly period includes the weekly and daily periods, the files can be produced once for all periods, using the month’s data as input. 

For convenience, `confinterval` outputs the experiment and `scheme intersection` passed to it as argument -- see `*confint_err.txt`.

### `watch times` 
This file is a static list of stream watch times from which to sample while calculating confidence intervals. Slow streams sample from a separate watch times file. The `pre_confinterval` program can generate these files, but they also reside in the root of the [data-release bucket](https://console.cloud.google.com/storage/browser/puffer-stanford-public/data-release-test). This avoids materializing the large amount of input data `pre_confinterval` needs to generate statistically sound watch times files. 

## Results

### CSVs
A set of CSVs is produced for each day, containing the data collected by Puffer. Appendix B of the Puffer [paper](https://sophon.stanford.edu/static/puffer/documents/puffer-paper.pdf) describes the format. The `private_analyze` program anonymizes the raw data, which contains IPs and other user information, assigning numerical identifiers to each session and stream.

In addition to the fields described in the appendix, these CSVs also contain a stream index. This index is used to group streams into sessions, but is not particularly meaningful otherwise. 

### *Stream* statistics 
A stream statistics file is produced for each day. Each line in this file summarizes a stream’s performance during the day. Stream statistics include SSIM and stall ratio as well as several other metrics.

Stream statistics are output in `*public_analyze_stats.txt`.

### *Scheme* statistics
A scheme statistics file is produced for each day, along with the week, two-week, and month period preceding each day (inclusive of the day itself). Each line in this file summarizes a scheme’s stall ratio and SSIM during the time period, as an average over each stream assigned to that scheme during the period. 

Averaging is performed only over days on which *all* schemes in the day’s experiment were run. This is important because network and TV station conditions change over time, so streams running on different days should not be directly compared (TODO: confirm). 

Scheme statistics, including 95% confidence intervals, are output in `*confint_out.txt` and plotted in `*plot.svg`. (TODO: friendlier filenames). Note that stall ratio is calculated using random sampling, so results will differ slightly across runs. 
